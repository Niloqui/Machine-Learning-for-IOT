{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import time as t\n",
    "\n",
    "from tensorflow import convert_to_tensor, float32, tensordot\n",
    "from tensorflow import abs as tfabs\n",
    "from tensorflow.io import serialize_tensor, write_file\n",
    "from tensorflow.math import log\n",
    "from tensorflow.signal import linear_to_mel_weight_matrix,mfccs_from_log_mel_spectrograms, stft\n",
    "dataset_dir = 'data/mini_speech_commands_datasets'\n",
    "\n",
    "mods_names = ['mlp','cnn','dscnn']\n",
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "metric = keras.metrics.SparseCategoricalAccuracy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "188/200 [===========================>..] - ETA: 0s - loss: 1.8202 - sparse_categorical_accuracy: 0.3868INFO:tensorflow:Assets written to: ./callback_test_chkp/mlp_chkp_best/assets\n",
      "200/200 [==============================] - 1s 5ms/step - loss: 1.8085 - sparse_categorical_accuracy: 0.3889 - val_loss: 1.5613 - val_sparse_categorical_accuracy: 0.4762\n",
      "Epoch 2/20\n",
      "187/200 [===========================>..] - ETA: 0s - loss: 1.3977 - sparse_categorical_accuracy: 0.5246INFO:tensorflow:Assets written to: ./callback_test_chkp/mlp_chkp_best/assets\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.3927 - sparse_categorical_accuracy: 0.5256 - val_loss: 1.3410 - val_sparse_categorical_accuracy: 0.5375\n",
      "Epoch 3/20\n",
      "192/200 [===========================>..] - ETA: 0s - loss: 1.1305 - sparse_categorical_accuracy: 0.6074INFO:tensorflow:Assets written to: ./callback_test_chkp/mlp_chkp_best/assets\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 1.1273 - sparse_categorical_accuracy: 0.6097 - val_loss: 1.2696 - val_sparse_categorical_accuracy: 0.5825\n",
      "Epoch 4/20\n",
      "196/200 [============================>.] - ETA: 0s - loss: 0.9295 - sparse_categorical_accuracy: 0.6790INFO:tensorflow:Assets written to: ./callback_test_chkp/mlp_chkp_best/assets\n",
      "200/200 [==============================] - 1s 6ms/step - loss: 0.9291 - sparse_categorical_accuracy: 0.6791 - val_loss: 1.2021 - val_sparse_categorical_accuracy: 0.6087\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.8366 - sparse_categorical_accuracy: 0.7050 - val_loss: 1.3160 - val_sparse_categorical_accuracy: 0.5925\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.7012 - sparse_categorical_accuracy: 0.7511 - val_loss: 1.3598 - val_sparse_categorical_accuracy: 0.6062\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.6076 - sparse_categorical_accuracy: 0.7800 - val_loss: 1.2922 - val_sparse_categorical_accuracy: 0.6413\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.5333 - sparse_categorical_accuracy: 0.8084 - val_loss: 1.3328 - val_sparse_categorical_accuracy: 0.6450\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4905 - sparse_categorical_accuracy: 0.8195 - val_loss: 1.4449 - val_sparse_categorical_accuracy: 0.6300\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4695 - sparse_categorical_accuracy: 0.8416 - val_loss: 1.6227 - val_sparse_categorical_accuracy: 0.6488\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3989 - sparse_categorical_accuracy: 0.8619 - val_loss: 1.5559 - val_sparse_categorical_accuracy: 0.6550\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3821 - sparse_categorical_accuracy: 0.8678 - val_loss: 1.7920 - val_sparse_categorical_accuracy: 0.6513\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.4225 - sparse_categorical_accuracy: 0.8677 - val_loss: 1.5905 - val_sparse_categorical_accuracy: 0.6700\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.3337 - sparse_categorical_accuracy: 0.8867 - val_loss: 1.6998 - val_sparse_categorical_accuracy: 0.6662\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2836 - sparse_categorical_accuracy: 0.9064 - val_loss: 1.8381 - val_sparse_categorical_accuracy: 0.6463\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2451 - sparse_categorical_accuracy: 0.9248 - val_loss: 1.8074 - val_sparse_categorical_accuracy: 0.6600\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2832 - sparse_categorical_accuracy: 0.9100 - val_loss: 1.7192 - val_sparse_categorical_accuracy: 0.6338\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1971 - sparse_categorical_accuracy: 0.9369 - val_loss: 2.2480 - val_sparse_categorical_accuracy: 0.6637\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.1726 - sparse_categorical_accuracy: 0.9483 - val_loss: 2.1751 - val_sparse_categorical_accuracy: 0.6812\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 1s 3ms/step - loss: 0.2370 - sparse_categorical_accuracy: 0.9292 - val_loss: 2.1957 - val_sparse_categorical_accuracy: 0.6538\n",
      "Model: \"sequential_18\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_6 (Flatten)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_36 (Dense)             (None, 256)               262400    \n",
      "_________________________________________________________________\n",
      "dense_37 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_38 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 396,040\n",
      "Trainable params: 396,040\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "25/25 - 0s - loss: 2.1884 - sparse_categorical_accuracy: 0.6288\n",
      "\n",
      "acc: 0.6287500262260437, size: 114327 Inference Latency 0.08365583419799805ms\n",
      "\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8834 - sparse_categorical_accuracy: 0.3367INFO:tensorflow:Assets written to: ./callback_test_chkp/cnn_chkp_best/assets\n",
      "200/200 [==============================] - 17s 85ms/step - loss: 1.8834 - sparse_categorical_accuracy: 0.3367 - val_loss: 1.6561 - val_sparse_categorical_accuracy: 0.4150\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4927 - sparse_categorical_accuracy: 0.4819INFO:tensorflow:Assets written to: ./callback_test_chkp/cnn_chkp_best/assets\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 1.4927 - sparse_categorical_accuracy: 0.4819 - val_loss: 1.4170 - val_sparse_categorical_accuracy: 0.5013\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2845 - sparse_categorical_accuracy: 0.5608INFO:tensorflow:Assets written to: ./callback_test_chkp/cnn_chkp_best/assets\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 1.2845 - sparse_categorical_accuracy: 0.5608 - val_loss: 1.2772 - val_sparse_categorical_accuracy: 0.5250\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1475 - sparse_categorical_accuracy: 0.6081INFO:tensorflow:Assets written to: ./callback_test_chkp/cnn_chkp_best/assets\n",
      "200/200 [==============================] - 18s 88ms/step - loss: 1.1475 - sparse_categorical_accuracy: 0.6081 - val_loss: 1.1962 - val_sparse_categorical_accuracy: 0.5838\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0679 - sparse_categorical_accuracy: 0.6325INFO:tensorflow:Assets written to: ./callback_test_chkp/cnn_chkp_best/assets\n",
      "200/200 [==============================] - 16s 82ms/step - loss: 1.0679 - sparse_categorical_accuracy: 0.6325 - val_loss: 1.1552 - val_sparse_categorical_accuracy: 0.6000\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9886 - sparse_categorical_accuracy: 0.6603INFO:tensorflow:Assets written to: ./callback_test_chkp/cnn_chkp_best/assets\n",
      "200/200 [==============================] - 18s 92ms/step - loss: 0.9886 - sparse_categorical_accuracy: 0.6603 - val_loss: 1.0663 - val_sparse_categorical_accuracy: 0.6375\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9267 - sparse_categorical_accuracy: 0.6808INFO:tensorflow:Assets written to: ./callback_test_chkp/cnn_chkp_best/assets\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.9267 - sparse_categorical_accuracy: 0.6808 - val_loss: 1.0143 - val_sparse_categorical_accuracy: 0.6300\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8737 - sparse_categorical_accuracy: 0.7013INFO:tensorflow:Assets written to: ./callback_test_chkp/cnn_chkp_best/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200/200 [==============================] - 18s 88ms/step - loss: 0.8737 - sparse_categorical_accuracy: 0.7013 - val_loss: 1.0041 - val_sparse_categorical_accuracy: 0.6425\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8135 - sparse_categorical_accuracy: 0.7248INFO:tensorflow:Assets written to: ./callback_test_chkp/cnn_chkp_best/assets\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.8135 - sparse_categorical_accuracy: 0.7248 - val_loss: 0.9189 - val_sparse_categorical_accuracy: 0.6913\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 17s 83ms/step - loss: 0.7840 - sparse_categorical_accuracy: 0.7356 - val_loss: 1.0497 - val_sparse_categorical_accuracy: 0.6338\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.7504 - sparse_categorical_accuracy: 0.7555 - val_loss: 1.0085 - val_sparse_categorical_accuracy: 0.6175\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7087 - sparse_categorical_accuracy: 0.7686INFO:tensorflow:Assets written to: ./callback_test_chkp/cnn_chkp_best/assets\n",
      "200/200 [==============================] - 17s 86ms/step - loss: 0.7087 - sparse_categorical_accuracy: 0.7686 - val_loss: 0.9029 - val_sparse_categorical_accuracy: 0.7100\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.6570 - sparse_categorical_accuracy: 0.7833 - val_loss: 1.0113 - val_sparse_categorical_accuracy: 0.6450\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.6366 - sparse_categorical_accuracy: 0.7898 - val_loss: 1.2047 - val_sparse_categorical_accuracy: 0.5938\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.5839 - sparse_categorical_accuracy: 0.8142 - val_loss: 0.9158 - val_sparse_categorical_accuracy: 0.7150\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.5598 - sparse_categorical_accuracy: 0.8214 - val_loss: 0.9519 - val_sparse_categorical_accuracy: 0.7000\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.5323 - sparse_categorical_accuracy: 0.8278 - val_loss: 0.9141 - val_sparse_categorical_accuracy: 0.6850\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 16s 81ms/step - loss: 0.5169 - sparse_categorical_accuracy: 0.8358 - val_loss: 0.9358 - val_sparse_categorical_accuracy: 0.6925\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 16s 78ms/step - loss: 0.4811 - sparse_categorical_accuracy: 0.8473 - val_loss: 1.0091 - val_sparse_categorical_accuracy: 0.6862\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 16s 79ms/step - loss: 0.4443 - sparse_categorical_accuracy: 0.8661 - val_loss: 0.9256 - val_sparse_categorical_accuracy: 0.6787\n",
      "Model: \"sequential_19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_36 (Conv2D)           (None, 15, 30, 128)       1152      \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 15, 30, 128)       512       \n",
      "_________________________________________________________________\n",
      "re_lu_36 (ReLU)              (None, 15, 30, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 7, 28, 128)        147456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_37 (Batc (None, 7, 28, 128)        512       \n",
      "_________________________________________________________________\n",
      "re_lu_37 (ReLU)              (None, 7, 28, 128)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 3, 26, 128)        147456    \n",
      "_________________________________________________________________\n",
      "batch_normalization_38 (Batc (None, 3, 26, 128)        512       \n",
      "_________________________________________________________________\n",
      "re_lu_38 (ReLU)              (None, 3, 26, 128)        0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_12  (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 8)                 1032      \n",
      "=================================================================\n",
      "Total params: 298,632\n",
      "Trainable params: 297,864\n",
      "Non-trainable params: 768\n",
      "_________________________________________________________________\n",
      "25/25 - 0s - loss: 0.9442 - sparse_categorical_accuracy: 0.6725\n",
      "\n",
      "acc: 0.6725000143051147, size: 260712 Inference Latency 0.3989994525909424ms\n",
      "\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.8628 - sparse_categorical_accuracy: 0.3558INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 1.8628 - sparse_categorical_accuracy: 0.3558 - val_loss: 1.6341 - val_sparse_categorical_accuracy: 0.4300\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.4655 - sparse_categorical_accuracy: 0.4836INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 33s 164ms/step - loss: 1.4655 - sparse_categorical_accuracy: 0.4836 - val_loss: 1.3311 - val_sparse_categorical_accuracy: 0.5238\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.2396 - sparse_categorical_accuracy: 0.5664INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.2396 - sparse_categorical_accuracy: 0.5664 - val_loss: 1.1936 - val_sparse_categorical_accuracy: 0.5713\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.1124 - sparse_categorical_accuracy: 0.6170INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 1.1124 - sparse_categorical_accuracy: 0.6170 - val_loss: 1.1179 - val_sparse_categorical_accuracy: 0.6112\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 1.0224 - sparse_categorical_accuracy: 0.6495INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 34s 169ms/step - loss: 1.0224 - sparse_categorical_accuracy: 0.6495 - val_loss: 1.0333 - val_sparse_categorical_accuracy: 0.6488\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.9640 - sparse_categorical_accuracy: 0.6705 - val_loss: 1.1039 - val_sparse_categorical_accuracy: 0.6388\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.9077 - sparse_categorical_accuracy: 0.6884INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 33s 167ms/step - loss: 0.9077 - sparse_categorical_accuracy: 0.6884 - val_loss: 0.9295 - val_sparse_categorical_accuracy: 0.7025\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8664 - sparse_categorical_accuracy: 0.7027INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.8664 - sparse_categorical_accuracy: 0.7027 - val_loss: 0.8976 - val_sparse_categorical_accuracy: 0.7113\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.8130 - sparse_categorical_accuracy: 0.7237INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 33s 165ms/step - loss: 0.8130 - sparse_categorical_accuracy: 0.7237 - val_loss: 0.8743 - val_sparse_categorical_accuracy: 0.7038\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.7895 - sparse_categorical_accuracy: 0.7236 - val_loss: 0.9086 - val_sparse_categorical_accuracy: 0.7237\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.7632 - sparse_categorical_accuracy: 0.7420 - val_loss: 0.8994 - val_sparse_categorical_accuracy: 0.6762\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.7136 - sparse_categorical_accuracy: 0.7623INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 34s 170ms/step - loss: 0.7136 - sparse_categorical_accuracy: 0.7623 - val_loss: 0.7917 - val_sparse_categorical_accuracy: 0.7337\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6876 - sparse_categorical_accuracy: 0.7647INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 32s 162ms/step - loss: 0.6876 - sparse_categorical_accuracy: 0.7647 - val_loss: 0.7915 - val_sparse_categorical_accuracy: 0.7588\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 31s 157ms/step - loss: 0.6807 - sparse_categorical_accuracy: 0.7702 - val_loss: 0.7969 - val_sparse_categorical_accuracy: 0.7212\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 32s 159ms/step - loss: 0.6504 - sparse_categorical_accuracy: 0.7734 - val_loss: 0.8153 - val_sparse_categorical_accuracy: 0.7300\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6194 - sparse_categorical_accuracy: 0.7966INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.6194 - sparse_categorical_accuracy: 0.7966 - val_loss: 0.7795 - val_sparse_categorical_accuracy: 0.7563\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - ETA: 0s - loss: 0.6076 - sparse_categorical_accuracy: 0.7927INFO:tensorflow:Assets written to: ./callback_test_chkp/dscnn_chkp_best/assets\n",
      "200/200 [==============================] - 33s 166ms/step - loss: 0.6076 - sparse_categorical_accuracy: 0.7927 - val_loss: 0.7268 - val_sparse_categorical_accuracy: 0.7462\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 32s 161ms/step - loss: 0.5660 - sparse_categorical_accuracy: 0.8087 - val_loss: 0.8251 - val_sparse_categorical_accuracy: 0.7188\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 32s 158ms/step - loss: 0.5649 - sparse_categorical_accuracy: 0.8095 - val_loss: 0.8387 - val_sparse_categorical_accuracy: 0.7163\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 31s 153ms/step - loss: 0.5412 - sparse_categorical_accuracy: 0.8225 - val_loss: 0.7686 - val_sparse_categorical_accuracy: 0.7337\n",
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_39 (Conv2D)           (None, 15, 30, 256)       2304      \n",
      "_________________________________________________________________\n",
      "batch_normalization_39 (Batc (None, 15, 30, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_39 (ReLU)              (None, 15, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_12 (Depthwi (None, 13, 28, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 13, 28, 256)       65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_40 (Batc (None, 13, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_40 (ReLU)              (None, 13, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "depthwise_conv2d_13 (Depthwi (None, 11, 26, 256)       2304      \n",
      "_________________________________________________________________\n",
      "conv2d_41 (Conv2D)           (None, 11, 26, 256)       65536     \n",
      "_________________________________________________________________\n",
      "batch_normalization_41 (Batc (None, 11, 26, 256)       1024      \n",
      "_________________________________________________________________\n",
      "re_lu_41 (ReLU)              (None, 11, 26, 256)       0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_13  (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 8)                 2056      \n",
      "=================================================================\n",
      "Total params: 143,112\n",
      "Trainable params: 141,576\n",
      "Non-trainable params: 1,536\n",
      "_________________________________________________________________\n",
      "25/25 - 1s - loss: 0.7939 - sparse_categorical_accuracy: 0.7300\n",
      "\n",
      "acc: 0.7300000190734863, size: 296447 Inference Latency 0.7081208229064941ms\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "seed = 42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "mfccs = True\n",
    "\n",
    "if not os.path.exists('data/mini_speech_commands'):\n",
    "    zip_path = tf.keras.utils.get_file(\n",
    "        origin='http://storage.googleapis.com/download.tensorflow.org/data/mini_speech_commands.zip',\n",
    "        fname='mini_speech_commands.zip',\n",
    "        extract=True,\n",
    "        cache_dir='.', cache_subdir='data')\n",
    "\n",
    "data_dir = os.path.join('.','data', 'mini_speech_commands')\n",
    "#filenames = tf.io.gfile.glob(str(data_dir) + '/*/*')\n",
    "#filenames = tf.random.shuffle(filenames)\n",
    "#n = len(filenames)\n",
    "\n",
    "\n",
    "\n",
    "LABELS = np.array(tf.io.gfile.listdir(str(data_dir))) \n",
    "LABELS = [label for label in LABELS if label != 'README.md']\n",
    "\n",
    "class SignalGenerator:\n",
    "    def __init__(self, labels, sampling_rate=16000, frame_length=1920 , frame_step=960, num_mel_bins=40,\n",
    "                 lower_freq=20, upper_freq=48000, num_coefficients=10, mfccs=False):\n",
    "        self.frame_length = frame_length\n",
    "        self.frame_step = frame_step\n",
    "        self.mel_inputs =  [num_mel_bins, None, sampling_rate, lower_freq, upper_freq]\n",
    "        self.mfccs_coeff = num_coefficients\n",
    "        self.labels=labels\n",
    "        self.sampling_rate=sampling_rate\n",
    "        num_spectrogram_bins = (frame_length) // 2 + 1\n",
    "\n",
    "        if mfccs:\n",
    "            self.l2mel_matrix = linear_to_mel_weight_matrix(\n",
    "                    self.num_mel_bins, num_spectrogram_bins, self.sampling_rate,\n",
    "                    lower_freq, upper_freq)\n",
    "            self.preprocess = self.preprocess_with_mfcc\n",
    "        else:\n",
    "            self.preprocess = self.preprocess_with_stft\n",
    "\n",
    "    def read(self, file_path):\n",
    "        parts = tf.strings.split(file_path, os.path.sep)\n",
    "        label = parts[-2]\n",
    "        label_id = tf.argmax(label == self.labels)\n",
    "        audio_binary = tf.io.read_file(file_path)\n",
    "        audio, _ = tf.audio.decode_wav(audio_binary)\n",
    "        audio = tf.squeeze(audio, axis=1)\n",
    "        return audio, label_id\n",
    "\n",
    "    def pad(self, audio):\n",
    "        zero_padding = tf.zeros([self.sampling_rate] - tf.shape(audio), dtype=tf.float32)\n",
    "        audio = tf.concat([audio,zero_padding],0)\n",
    "        audio.set_shape([self.sampling_rate])\n",
    "        return audio\n",
    "\n",
    "    def get_spectrogram(self, audio):\n",
    "        tfstft = stft(audio, frame_length=self.frame_length, frame_step=self.frame_step,fft_length=self.frame_length)\n",
    "        spectrogram = tf.abs(tfstft)\n",
    "        return spectrogram\n",
    "\n",
    "    def get_mfcc(self, spectrogram):\n",
    "        mel_spectrogram = tensordot(spectrogram, self.l2mel_matrix, 1)\n",
    "        log_mel_spectrogram = log(mel_spectrogram + 1e-6)\n",
    "        mfccs = mfccs_from_log_mel_spectrograms(log_mel_spectrogram)[..., :self.mfccs_coeff]\n",
    "        return mfccs\n",
    "\n",
    "    def preprocess_with_stft(self, file_path):\n",
    "        audio, label = self.read(file_path)\n",
    "        audio = self.pad(audio)\n",
    "        spectrogram = self.get_spectrogram(audio)\n",
    "        spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "        spectrogram = tf.image.resize(spectrogram, [32,32])\n",
    "        return spectrogram, label\n",
    "\n",
    "    def preprocess_with_mfcc(self, file_path):\n",
    "        audio, label = self.read(file_path)\n",
    "        audio = self.pad(audio)\n",
    "        spectrogram = self.get_spectrogram(audio)\n",
    "        spectrogram = tf.expand_dims(spectrogram, -1)\n",
    "        mfccs = get_mfcc(spectrogram)\n",
    "        return mfccs, label\n",
    "\n",
    "    def make_dataset(self, files, train):\n",
    "        ds = tf.data.Dataset.from_tensor_slices(files)\n",
    "        ds = ds.map(self.preprocess, num_parallel_calls=4)\n",
    "        ds = ds.batch(32)\n",
    "        ds = ds.cache()\n",
    "\n",
    "        if train:\n",
    "            ds = ds.shuffle(100, reshuffle_each_iteration=True)\n",
    "\n",
    "        return ds\n",
    "\n",
    "\n",
    "if not os.path.exists(dataset_dir):\n",
    "    os.mkdir(dataset_dir)\n",
    "    train_files = tf.strings.split(tf.io.read_file('./kws_train_split.txt'),sep='\\n')[:-1]\n",
    "    val_files = tf.strings.split(tf.io.read_file('./kws_val_split.txt'),sep='\\n')[:-1]\n",
    "    test_files = tf.strings.split(tf.io.read_file('./kws_test_split.txt'),sep='\\n')[:-1]\n",
    "    generator = SignalGenerator(LABELS)\n",
    "    train_ds = generator.make_dataset(train_files, True)\n",
    "    val_ds = generator.make_dataset(val_files, False)\n",
    "    test_ds = generator.make_dataset(test_files, False)\n",
    "    tf.data.experimental.save(train_ds, f'{dataset_dir}/th_train')\n",
    "    tf.data.experimental.save(val_ds, f'{dataset_dir}/th_val')\n",
    "    tf.data.experimental.save(test_ds, f'{dataset_dir}/th_test')\n",
    "    \n",
    "\n",
    "stride = [2,2] if not mfccs else [2,1]\n",
    "\n",
    "MLP = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(units=256,activation=keras.activations.relu),\n",
    "    keras.layers.Dense(units=256,activation=keras.activations.relu),\n",
    "    keras.layers.Dense(units=256,activation=keras.activations.relu),\n",
    "    keras.layers.Dense(units=len(LABELS))\n",
    "])\n",
    "\n",
    "CNN = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=[3,3], strides = stride, use_bias=False),\n",
    "    keras.layers.BatchNormalization(momentum=0.1),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=[3,3], strides = stride, use_bias=False),\n",
    "    keras.layers.BatchNormalization(momentum=0.1),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.Conv2D(filters=128, kernel_size=[3,3], strides = stride, use_bias=False),\n",
    "    keras.layers.BatchNormalization(momentum=0.1),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(units=len(LABELS))\n",
    "])\n",
    "\n",
    "DSCNN = keras.Sequential([\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=[3, 3], strides=stride, use_bias=False),\n",
    "    keras.layers.BatchNormalization(momentum=0.1),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1], use_bias=False),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=[1, 1], strides=[1, 1], use_bias=False),\n",
    "    keras.layers.BatchNormalization(momentum=0.1),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.DepthwiseConv2D(kernel_size=[3, 3], strides=[1, 1], use_bias=False),\n",
    "    keras.layers.Conv2D(filters=256, kernel_size=[1, 1], strides=[1, 1], use_bias=False),\n",
    "    keras.layers.BatchNormalization(momentum=0.1),\n",
    "    keras.layers.ReLU(),\n",
    "    keras.layers.GlobalAveragePooling2D(),\n",
    "    keras.layers.Dense(units=len(LABELS))\n",
    "])\n",
    "\n",
    "models = [MLP,CNN,DSCNN]\n",
    "\n",
    "for i,model in enumerate(models):\n",
    "    model.compile(optimizer='adam',loss=loss, metrics=[metric])\n",
    "    cp_callback = keras.callbacks.ModelCheckpoint(\n",
    "        f'./callback_test_chkp/{mods_names[i]}_chkp_best',\n",
    "        monitor='val_loss',\n",
    "        verbose=0, \n",
    "        save_best_only=True,\n",
    "        save_weights_only=False,\n",
    "        mode='auto',\n",
    "        save_freq='epoch'\n",
    "    )\n",
    "    model.fit(train_ds, batch_size=32, epochs=20, validation_data=val_ds,callbacks=[cp_callback])\n",
    "    model.summary()\n",
    "    start = t.time()\n",
    "    test_loss, test_acc2 = model.evaluate(test_ds, verbose=2)\n",
    "    end = t.time() - start\n",
    "    msize = os.path.getsize(f'./callback_test_chkp/{mods_names[i]}_chkp_best/saved_model.pb')\n",
    "    print()\n",
    "    print(f'acc: {test_acc2}, size: {msize} Inference Latency {end}ms')\n",
    "    print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## saves and run tflite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size of basic model: 146.421875kB\n",
      "size of optimized model: 146.421875kB \n",
      "compressed: 115.79296875kB\n",
      "input:  <class 'numpy.float32'>\n",
      "output:  <class 'numpy.float32'>\n",
      "accuracy: 0.72625 tflite size: 146.421875kB compressed: 115.79296875kB time: 4.929123640060425ms\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.lite as tflite\n",
    "import zlib\n",
    "#import tensorflow_model_optimization as tfmot\n",
    "#pruning_params = {'pruning_schedule':tfmot.sparsity.keras.PolynomialDecay(initial_sparsity=0.30, \n",
    "#                                                                          final_sparsity=0.8,\n",
    "#                                                                          begin_step=len(train_ds)*5,\n",
    "#                                                                          end_step=len(train_ds)*15)}\n",
    "#prune_low_magnitude = tfmot.sparsity.keras.prune_low_magnitude\n",
    "\n",
    "\n",
    "tensor_specs = (tf.TensorSpec([None,32,32,1],dtype=tf.float32),tf.TensorSpec([None,],dtype=tf.int64))\n",
    "train_ds = tf.data.experimental.load(f'{dataset_dir}/th_train',tensor_specs)\n",
    "val_ds = tf.data.experimental.load(f'{dataset_dir}/th_val', tensor_specs)\n",
    "test_ds = tf.data.experimental.load(f'{dataset_dir}/th_test',tensor_specs)\n",
    "test_ds = test_ds.unbatch().batch(1)\n",
    "\n",
    "def convert(img, target_type_min, target_type_max, target_type):\n",
    "    img = img\n",
    "    imin = img.min()\n",
    "    imax = img.max()\n",
    "\n",
    "    a = (target_type_max - target_type_min) / (imax - imin)\n",
    "    b = target_type_max - a * imax\n",
    "    new_img = (a * img + b).astype(target_type)\n",
    "    return new_img\n",
    "\n",
    "def representative_dataset_gen():\n",
    "    for x, _ in train_ds.take(100):\n",
    "        yield [x]\n",
    "    \n",
    "for mod in mods_names:\n",
    "    #saving\n",
    "    tflite_dirs = './tflite_models'\n",
    "    \n",
    "    if mod != 'dscnn':\n",
    "        continue\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(f'./callback_test_chkp/{mod}_chkp_best/')\n",
    "    tflite_model = converter.convert()\n",
    "    if not os.path.exists(tflite_dirs): \n",
    "        os.mkdir(tflite_dirs)\n",
    "    with open(tflite_dirs+f'/{mod}_basic.tflite', 'wb') as f:\n",
    "        f.write(tflite_opt_model)\n",
    "    tflo_size=os.path.getsize(tflite_dirs+f\"/{mod}_basic.tflite\")\n",
    "    print(f'size of basic model: {tflo_size/1024}kB')\n",
    "    \n",
    "    '''\n",
    "    tflite_opt_model = converter.convert()\n",
    "    if not os.path.exists(tflite_dirs): \n",
    "        os.mkdir(tflite_dirs)\n",
    "    with open(tflite_dirs+f'/{mod}_opt.tflite', 'wb') as f:\n",
    "        f.write(tflite_opt_model)\n",
    "    tflo_size=os.path.getsize(tflite_dirs+f\"/{mod}_opt.tflite\")\n",
    "    print(f'size of optimized model: {tflo_size/1024}kB')\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(tflite_dirs+f'/{mod}_opt.tflite')\n",
    "    '''\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model(f'./callback_test_chkp/{mod}_chkp_best/')\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    #converter.representative_dataset = representative_dataset_gen\n",
    "    #converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "    #converter.inference_input_type = tf.uint8  # or tf.uint8\n",
    "    #converter.inference_output_type = tf.uint8 \n",
    "    tflite_quant_model = converter.convert()\n",
    "    \n",
    "    \n",
    "    if not os.path.exists(tflite_dirs): \n",
    "        os.mkdir(tflite_dirs)\n",
    "    with open(tflite_dirs+f'/{mod}.tflite', 'wb') as f:\n",
    "        f.write(tflite_quant_model)\n",
    "    tfl_size=os.path.getsize(tflite_dirs+f\"/{mod}.tflite\")\n",
    "    with open(tflite_dirs+f\"/{mod}_compressed.tflite.zlib\", 'wb') as fp:\n",
    "        tflite_compressed = zlib.compress(tflite_quant_model)\n",
    "        fp.write(tflite_compressed)\n",
    "    tflc_size=os.path.getsize(tflite_dirs+f\"/{mod}_compressed.tflite.zlib\")\n",
    "    \n",
    "    print(f'size of optimized model: {tfl_size/1024}kB \\ncompressed: {tflc_size/1024}kB')\n",
    "    \n",
    "    interpreter = tflite.Interpreter(model_path = tflite_dirs+f\"/{mod}.tflite\")\n",
    "    interpreter.allocate_tensors()\n",
    "    # Get input and output tensors.\n",
    "    input_details = interpreter.get_input_details()\n",
    "    print('input: ', input_details[0]['dtype'])\n",
    "    output_details = interpreter.get_output_details()\n",
    "    print('output: ', output_details[0]['dtype'])\n",
    "\n",
    "    input_shape = input_details[0]['shape']\n",
    "    num_corr = 0\n",
    "    num = 0\n",
    "    start = t.time()\n",
    "    for input_data,label in test_ds:\n",
    "        #input_data = convert(input_data, 0, 255, np.uint8)\n",
    "        #label = convert(label, 0, 255, np.uint8)\n",
    "        #input_data = tf.quantization.quantize(input_data,min(input_data),max(input_data),tf.quint8)\n",
    "        #label = tf.quantization.quantize(label,min(LABELS),max(LABELS),tf.quint8)\n",
    "        num += 1\n",
    "        interpreter.set_tensor(input_details[0]['index'], input_data)\n",
    "        interpreter.invoke()\n",
    "        output_data = np.argmax(interpreter.get_tensor(output_details[0]['index']))\n",
    "        y_pred = tf.constant([output_data],dtype=tf.int64)\n",
    "        if label.numpy()[0] == output_data:\n",
    "            num_corr+=1\n",
    "    end = t.time() - start\n",
    "    print(f'accuracy: {num_corr/num} tflite size: {tfl_size/1024}kB compressed: {tflc_size/1024}kB time: {end}ms')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = prune_low_magnitude(model, **pruning_params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": ".venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
